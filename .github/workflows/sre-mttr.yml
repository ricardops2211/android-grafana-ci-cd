name: sre-mttr-loki-v1

on:
  push:
    branches: [ "sre-richie" ]
  workflow_dispatch:
    inputs:
      chaos_minutes:
        description: "Duración falla (min)"
        required: false
        default: "2"
      mttr_slo_seconds:
        description: "SLO MTTR (s)"
        required: false
        default: "300"

concurrency:
  group: sre-mttr-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  mttr-lab:
    runs-on: self-hosted
    env:
      NAMESPACE: sre-demo
      DEPLOYMENT: api-demo
      APP_LABEL: api-demo
      RUN_ID: ${{ github.run_id }}

    steps:
      - uses: actions/checkout@v4

      - name: Set defaults for chaos & SLO
        id: defs
        shell: bash
        run: |
          CHAOS="${{ github.event.inputs.chaos_minutes }}"
          SLO="${{ github.event.inputs.mttr_slo_seconds }}"
          [ -z "$CHAOS" ] && CHAOS=2
          [ -z "$SLO" ] && SLO=300
          echo "chaos=$CHAOS" >> "$GITHUB_OUTPUT"
          echo "slo=$SLO"   >> "$GITHUB_OUTPUT"

      - name: kubectl setup
        uses: ./.github/actions/kubectl-setup
        with:
          kubeconfig_b64: ${{ secrets.KUBECONFIG_B64 }}

      - name: Helm repos & namespaces
        shell: bash
        run: |
          set -euo pipefail
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          kubectl get ns observability >/dev/null 2>&1 || kubectl create ns observability
          kubectl get ns monitoring   >/dev/null 2>&1 || kubectl create ns monitoring
          kubectl get ns $NAMESPACE   >/dev/null 2>&1 || kubectl create ns $NAMESPACE

      - name: Build & load app image (on push)
        if: ${{ github.event_name == 'push' }}
        shell: bash
        run: |
          set -euo pipefail
          docker build -t api-demo:local ./app
          kind load docker-image api-demo:local --name sre-demo

      - name: Render monitoring values (Alertmanager Slack)
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        shell: bash
        run: |
          set -euo pipefail
          if command -v envsubst >/dev/null 2>&1; then R=envsubst;
          elif [ -x ./tools/envsubst ]; then R=./tools/envsubst;
          else echo "ERROR: envsubst no disponible. Incluye tools/envsubst o usa sed." >&2; exit 1; fi
          (cd k8s && $R < monitoring-values.yaml > monitoring-values.rendered.yaml)
          grep -q "hooks.slack.com" k8s/monitoring-values.rendered.yaml || echo "::warning::Slack URL no inyectada"

      - name: Install kube-prometheus-stack (AM/Prom)
        shell: bash
        run: |
          set -euo pipefail
          helm upgrade --install kps prometheus-community/kube-prometheus-stack \
            -n monitoring -f k8s/monitoring-values.rendered.yaml
          kubectl -n monitoring wait --for=condition=Available --timeout=600s \
            prometheus/kps-kube-prometheus-stack-prometheus || true
          kubectl -n monitoring wait --for=condition=Available --timeout=600s \
            alertmanager/kps-kube-prometheus-stack-alertmanager || true

      # === NO instala Loki/Promtail/Grafana: solo verifica Loki ya desplegado en el clúster ===
      - name: Check Loki on cluster (no install)
        id: loki_ready
        shell: bash
        run: |
          set -euo pipefail
          if kubectl -n observability wait --for=condition=Ready --timeout=240s pod -l app.kubernetes.io/name=loki; then
            echo "ok=true" >> "$GITHUB_OUTPUT"
          else
            echo "ok=false" >> "$GITHUB_OUTPUT"
            echo "---- Pods Loki ----"
            kubectl -n observability get po -l app.kubernetes.io/name=loki -o wide || true
            echo "---- Describe Loki ----"
            kubectl -n observability describe po -l app.kubernetes.io/name=loki || true
            echo "---- Logs Loki (tail) ----"
            kubectl -n observability logs -l app.kubernetes.io/name=loki --tail=200 || true
          fi

      - name: Deploy app
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f k8s/deployment.yaml
          kubectl -n $NAMESPACE rollout status deploy/$DEPLOYMENT --timeout=300s

      - name: Apply Grafana dashboard (ConfigMap sidecar)
        shell: bash
        run: |
          set -euo pipefail
          awk 'BEGIN{print "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dashboard-mttr\n  namespace: observability\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  sre-mttr-loki.json: |"} {print "    "$0}' k8s/grafana-dashboard-mttr.json > k8s/grafana-dashboard-configmap.yaml
          kubectl -n observability apply -f k8s/grafana-dashboard-configmap.yaml

      # === Solo si Loki está OK ===
      - name: Port-forward Loki (inline)
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        shell: bash
        run: |
          set -euo pipefail
          POD=$(kubectl -n observability get pod -l app.kubernetes.io/name=loki -o jsonpath='{.items[0].metadata.name}')
          kubectl -n observability port-forward pod/"$POD" 3100:3100 >/tmp/pf.log 2>&1 & echo $! >/tmp/pf.pid
          for i in {1..60}; do
            curl -fsS http://127.0.0.1:3100/ready >/dev/null && break
            sleep 1
          done
          curl -fsS http://127.0.0.1:3100/ready >/dev/null || (echo "Loki /ready no responde"; exit 1)

      - name: Incident start
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        id: start
        uses: ./.github/actions/loki-push
        with:
          type: incident_start
          run_id: ${{ env.RUN_ID }}
          app: ${{ env.APP_LABEL }}
          message: "incident start caused_by=chaos"
          loki_url: "http://127.0.0.1:3100"

      - name: Chaos ON
        uses: ./.github/actions/chaos-toggle
        with:
          namespace: ${{ env.NAMESPACE }}
          deployment: ${{ env.DEPLOYMENT }}
          fail_rate: "1.0"

      - name: Hold chaos
        shell: bash
        run: |
          set -euo pipefail
          CHAOS=${{ steps.defs.outputs.chaos }}
          sleep $((60 * CHAOS))

      - name: Chaos OFF
        uses: ./.github/actions/chaos-toggle
        with:
          namespace: ${{ env.NAMESPACE }}
          deployment: ${{ env.DEPLOYMENT }}
          fail_rate: "0.0"

      - name: Wait stable
        uses: ./.github/actions/wait-stable
        with:
          namespace: ${{ env.NAMESPACE }}
          app_label: ${{ env.APP_LABEL }}

      - name: Incident end
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        id: end
        uses: ./.github/actions/loki-push
        with:
          type: incident_end
          run_id: ${{ env.RUN_ID }}
          app: ${{ env.APP_LABEL }}
          message: "incident end status=recovered"
          loki_url: "http://127.0.0.1:3100"

      - name: Calcular MTTD/MTTR
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        id: calc
        uses: ./.github/actions/loki-calc-mttr
        with:
          start_ns: ${{ steps.start.outputs.ts_ns }}
          end_ns:   ${{ steps.end.outputs.ts_ns }}
          query_error: '{app="${{ env.APP_LABEL }}"} |= "ERROR"'
          loki_url: "http://127.0.0.1:3100"

      - name: Upload report
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        uses: ./.github/actions/upload-report
        with:
          run_id:       ${{ env.RUN_ID }}
          mttr_seconds: ${{ steps.calc.outputs.mttr_seconds }}
          mttd_seconds: ${{ steps.calc.outputs.mttd_seconds }}

      - name: Enforce SLO
        if: ${{ steps.loki_ready.outputs.ok == 'true' }}
        uses: ./.github/actions/enforce-slo
        with:
          mttr_seconds: ${{ steps.calc.outputs.mttr_seconds }}
          slo_seconds:  ${{ steps.defs.outputs.slo }}

      - name: Cleanup port-forward
        if: always()
        shell: bash
        run: |
          if [ -f /tmp/pf.pid ]; then
            kill "$(cat /tmp/pf.pid)" 2>/dev/null || true
            rm -f /tmp/pf.pid
          fi
